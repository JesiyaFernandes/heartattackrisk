{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1lnm6DoCYRQd834I5Diy6OJXSdFYw3OES",
      "authorship_tag": "ABX9TyMsD8LXOTgJKpYTVjIlmZip",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JesiyaFernandes/heartattackrisk/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDhMYPY_Nm3L",
        "outputId": "aaf8ac1f-3f66-4a2c-9367-d5ec6f2ad265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/data_csv.csv\n",
            "  PatientID eye       filename  gender  thickness  label  group  True_age  \\\n",
            "0   2491006   R  2491006_R.png       0        0.8      0      1        63   \n",
            "1   2491006   L  2491006_L.png       0        0.8      0      1        63   \n",
            "2   3730004   R  3730004_R.png       1        1.2      1      1        61   \n",
            "3   3730004   L  3730004_L.png       1        1.2      1      1        61   \n",
            "4   3730006   R  3730006_R.png       1        1.2      1      1        64   \n",
            "\n",
            "   age_norm  \n",
            "0  0.684932  \n",
            "1  0.684932  \n",
            "2  0.657534  \n",
            "3  0.657534  \n",
            "4  0.698630  \n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "json_path = \"/content/drive/MyDrive/data_info.json\"   # update path\n",
        "csv_path  = \"/content/drive/MyDrive/data_csv.csv\"\n",
        "\n",
        "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw = json.load(f)   # raw is a dict: { \"2491006\": { ... }, \"3730004\": { ... }, ... }\n",
        "\n",
        "rows = []\n",
        "\n",
        "for patient_id, info in raw.items():\n",
        "    # common fields\n",
        "    gender    = info.get(\"gender\")\n",
        "    thickness = info.get(\"thickness\")\n",
        "    label     = info.get(\"label\")   # 0/1 – this is your risk label\n",
        "    group     = info.get(\"group\")\n",
        "    true_age  = info.get(\"True_age\")\n",
        "    age_norm  = info.get(\"age\")     # normalized age if present\n",
        "\n",
        "    # right eye\n",
        "    if \"right_eye\" in info and info[\"right_eye\"]:\n",
        "        rows.append({\n",
        "            \"PatientID\": patient_id,\n",
        "            \"eye\": \"R\",\n",
        "            \"filename\": info[\"right_eye\"],\n",
        "            \"gender\": gender,\n",
        "            \"thickness\": thickness,\n",
        "            \"label\": label,\n",
        "            \"group\": group,\n",
        "            \"True_age\": true_age,\n",
        "            \"age_norm\": age_norm,\n",
        "        })\n",
        "\n",
        "    # left eye\n",
        "    if \"left_eye\" in info and info[\"left_eye\"]:\n",
        "        rows.append({\n",
        "            \"PatientID\": patient_id,\n",
        "            \"eye\": \"L\",\n",
        "            \"filename\": info[\"left_eye\"],\n",
        "            \"gender\": gender,\n",
        "            \"thickness\": thickness,\n",
        "            \"label\": label,\n",
        "            \"group\": group,\n",
        "            \"True_age\": true_age,\n",
        "            \"age_norm\": age_norm,\n",
        "        })\n",
        "\n",
        "# Create DataFrame and save to CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"Saved:\", csv_path)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preprocessing pipeline for retinal fundus dataset\n",
        "- CSV cleaning and encoding\n",
        "- Patient-level train/val/test split\n",
        "- Image cropping, resizing, and normalization-ready storage\n",
        "\n",
        "Author: <your name>\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Fundus_CIMT_2903_cropped_512\")  # folder containing images\n",
        "CSV_PATH = Path(\"/content/data_csv.csv\")               # your CSV file\n",
        "OUTPUT_ROOT = Path(\"/content/drive/MyDrive/processed_dataset\")\n",
        "\n",
        "IMAGE_EXT = \".png\"\n",
        "IMAGE_SIZE = 384              # final square size (e.g. 224, 299, 384)\n",
        "RANDOM_SEED = 42\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15              # test will be 1 - TRAIN_RATIO - VAL_RATIO\n",
        "\n",
        "# Column names in your CSV (adjust if different)\n",
        "COL_PATIENT_ID = \"PatientID\"\n",
        "COL_FILENAME = \"filename\"\n",
        "COL_EYE = \"eye\"               # 'L' or 'R'\n",
        "COL_GENDER = \"gender\"         # 0/1 or M/F\n",
        "COL_LABEL = \"label\"           # risk label\n",
        "COL_GROUP = \"group\"           # optional extra grouping\n",
        "\n",
        "# -----------------------------\n",
        "# Utility functions\n",
        "# -----------------------------\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def load_and_clean_csv(csv_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Load CSV, drop duplicates/NA, standardize dtypes, and attach image paths.\"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Basic cleaning\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.dropna(subset=[COL_PATIENT_ID, COL_FILENAME])\n",
        "\n",
        "    # Ensure types\n",
        "    df[COL_PATIENT_ID] = df[COL_PATIENT_ID].astype(str)\n",
        "    df[COL_FILENAME] = df[COL_FILENAME].astype(str)\n",
        "\n",
        "    # Standardize eye column if present\n",
        "    if COL_EYE in df.columns:\n",
        "        df[COL_EYE] = df[COL_EYE].str.upper().str.strip()\n",
        "\n",
        "    # Encode gender if text; if already 0/1, this will have no effect\n",
        "    if COL_GENDER in df.columns and not np.issubdtype(df[COL_GENDER].dtype, np.number):\n",
        "        df[COL_GENDER] = (\n",
        "            df[COL_GENDER]\n",
        "            .str.upper()\n",
        "            .str.strip()\n",
        "            .map({\"M\": 1, \"MALE\": 1, \"F\": 0, \"FEMALE\": 0})\n",
        "        )\n",
        "\n",
        "    # Attach full image path\n",
        "    df[\"image_path\"] = df[COL_FILENAME].apply(\n",
        "        lambda x: str(DATA_ROOT / x)\n",
        "    )\n",
        "\n",
        "    # Filter rows where image file actually exists\n",
        "    df[\"image_exists\"] = df[\"image_path\"].apply(os.path.exists)\n",
        "    missing = df[~df[\"image_exists\"]]\n",
        "    if len(missing) > 0:\n",
        "        print(f\"Warning: {len(missing)} entries without images will be dropped.\")\n",
        "        df = df[df[\"image_exists\"]]\n",
        "\n",
        "    df = df.drop(columns=[\"image_exists\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def crop_fundus_circle(img: np.ndarray, padding: int = 10) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Simple cropping of fundus images:\n",
        "    - Convert to gray\n",
        "    - Threshold to find the circular fundus region\n",
        "    - Crop to bounding box with small padding.\n",
        "    Inspired by common fundus pre-processing approaches. [web:23][web:27][web:28]\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Normalize and threshold\n",
        "    gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, mask = cv2.threshold(gray_blur, 10, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find bounding box of the non-zero region\n",
        "    coords = cv2.findNonZero(mask)\n",
        "    if coords is None:\n",
        "        return img  # fallback: return original\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(coords)\n",
        "\n",
        "    x0 = max(x - padding, 0)\n",
        "    y0 = max(y - padding, 0)\n",
        "    x1 = min(x + w + padding, img.shape[1])\n",
        "    y1 = min(y + h + padding, img.shape[0])\n",
        "\n",
        "    cropped = img[y0:y1, x0:x1]\n",
        "    return cropped\n",
        "\n",
        "\n",
        "def preprocess_image(path: str, image_size: int = 384) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Load an image from disk, crop border, resize to fixed size.\n",
        "    Returns BGR uint8 image; normalization will typically be done in the\n",
        "    dataloader before feeding into the network. [web:28][web:31][web:37]\n",
        "    \"\"\"\n",
        "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not read image: {path}\")\n",
        "\n",
        "    img = crop_fundus_circle(img, padding=10)\n",
        "    img = cv2.resize(img, (image_size, image_size), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def patient_level_split(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split dataframe into train/val/test at patient level to avoid leakage. [web:29][web:32][web:35][web:41]\n",
        "    \"\"\"\n",
        "    patients = df[COL_PATIENT_ID].unique()\n",
        "    train_patients, temp_patients = train_test_split(\n",
        "        patients, test_size=(1 - TRAIN_RATIO), random_state=RANDOM_SEED, shuffle=True\n",
        "    )\n",
        "\n",
        "    val_size_rel = VAL_RATIO / (1 - TRAIN_RATIO)\n",
        "    val_patients, test_patients = train_test_split(\n",
        "        temp_patients, test_size=(1 - val_size_rel), random_state=RANDOM_SEED, shuffle=True\n",
        "    )\n",
        "\n",
        "    train_df = df[df[COL_PATIENT_ID].isin(train_patients)].reset_index(drop=True)\n",
        "    val_df = df[df[COL_PATIENT_ID].isin(val_patients)].reset_index(drop=True)\n",
        "    test_df = df[df[COL_PATIENT_ID].isin(test_patients)].reset_index(drop=True)\n",
        "\n",
        "    print(f\"Patients: train={len(train_patients)}, val={len(val_patients)}, test={len(test_patients)}\")\n",
        "    print(f\"Images:   train={len(train_df)}, val={len(val_df)}, test={len(test_df)}\")\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def save_split_and_images(\n",
        "    df: pd.DataFrame,\n",
        "    split_name: str,\n",
        "    output_root: Path,\n",
        "    image_size: int = 384,\n",
        "    limit: int | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Preprocess and copy images into structured folders:\n",
        "        output_root/split_name/images/\n",
        "    Also save the CSV with updated relative paths.\n",
        "    \"\"\"\n",
        "    split_root = output_root / split_name\n",
        "    img_out_dir = split_root / \"images\"\n",
        "    split_root.mkdir(parents=True, exist_ok=True)\n",
        "    img_out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    processed_paths = []\n",
        "    rows = df if limit is None else df.iloc[:limit].copy()\n",
        "\n",
        "    for idx, row in rows.iterrows():\n",
        "        src = row[\"image_path\"]\n",
        "        # Preserve filename\n",
        "        fname = os.path.basename(src)\n",
        "        dst = img_out_dir / fname\n",
        "\n",
        "        try:\n",
        "            img = preprocess_image(src, image_size=image_size)\n",
        "            cv2.imwrite(str(dst), img)\n",
        "            processed_paths.append(str(dst.relative_to(split_root)))\n",
        "        except Exception as e:\n",
        "            print(f\"[{split_name}] Skipping {src}: {e}\")\n",
        "            processed_paths.append(None)\n",
        "\n",
        "    rows[\"processed_path\"] = processed_paths\n",
        "    rows = rows.dropna(subset=[\"processed_path\"])\n",
        "\n",
        "    # Save CSV for this split\n",
        "    csv_out = split_root / f\"{split_name}_metadata.csv\"\n",
        "    rows.to_csv(csv_out, index=False)\n",
        "    print(f\"Saved {len(rows)} records for {split_name} to {csv_out}\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main entrypoint\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    set_seed(RANDOM_SEED)\n",
        "\n",
        "    # 1. Load & clean CSV\n",
        "    df_all = load_and_clean_csv(CSV_PATH)\n",
        "    print(f\"Total valid rows after cleaning: {len(df_all)}\")\n",
        "\n",
        "    # 2. Optional: basic sanity checks\n",
        "    if COL_LABEL in df_all.columns:\n",
        "        print(\"Label distribution:\")\n",
        "        print(df_all[COL_LABEL].value_counts(dropna=False))\n",
        "\n",
        "    # 3. Patient-level split\n",
        "    train_df, val_df, test_df = patient_level_split(df_all)\n",
        "\n",
        "    # 4. Save splits and preprocessed images\n",
        "    #    Remove `limit` argument to process the full dataset.\n",
        "    OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "    save_split_and_images(train_df, \"train\", OUTPUT_ROOT, image_size=IMAGE_SIZE)\n",
        "    save_split_and_images(val_df, \"val\", OUTPUT_ROOT, image_size=IMAGE_SIZE)\n",
        "    save_split_and_images(test_df, \"test\", OUTPUT_ROOT, image_size=IMAGE_SIZE)\n",
        "\n",
        "    print(\"Preprocessing completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tLIdPz7OZD4",
        "outputId": "bcec4409-b7bf-4310-da3c-fe3f70df29e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total valid rows after cleaning: 5806\n",
            "Label distribution:\n",
            "label\n",
            "1    4108\n",
            "0    1698\n",
            "Name: count, dtype: int64\n",
            "Patients: train=2032, val=435, test=436\n",
            "Images:   train=4064, val=870, test=872\n",
            "Saved 4064 records for train to /content/drive/MyDrive/processed_dataset/train/train_metadata.csv\n",
            "Saved 870 records for val to /content/drive/MyDrive/processed_dataset/val/val_metadata.csv\n",
            "Saved 872 records for test to /content/drive/MyDrive/processed_dataset/test/test_metadata.csv\n",
            "Preprocessing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Pure image feature extraction for retinal fundus dataset.\n",
        "Assumes directory structure:\n",
        "  PROCESSED_ROOT/\n",
        "      train/images/*.png\n",
        "      val/images/*.png\n",
        "      test/images/*.png\n",
        "\n",
        "Outputs:\n",
        "  PROCESSED_ROOT/{split}/{split}_features.npy\n",
        "  PROCESSED_ROOT/{split}/{split}_filenames.npy\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "import cv2\n",
        "\n",
        "# -----------------------------\n",
        "# Configuration\n",
        "# -----------------------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "PROCESSED_ROOT = Path(\"/content/drive/MyDrive/processed_dataset\")\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 384\n",
        "FEATURE_DIM = 1280  # EfficientNet-B0 last conv feature size\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset and transforms\n",
        "# -----------------------------\n",
        "\n",
        "class FundusImageOnlyDataset(Dataset):\n",
        "    def __init__(self, images_dir: Path, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = sorted([\n",
        "            p for p in images_dir.glob(\"*\")\n",
        "            if p.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        img = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(str(path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, str(path.name)\n",
        "\n",
        "# ImageNet normalization for pretrained EfficientNet. [web:30][web:62]\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "\n",
        "# -----------------------------\n",
        "# Feature extractor model\n",
        "# -----------------------------\n",
        "\n",
        "def build_feature_extractor():\n",
        "    \"\"\"\n",
        "    EfficientNet-B0 pretrained on ImageNet, used only as feature extractor\n",
        "    (classifier head removed). [web:30][web:62][web:63]\n",
        "    \"\"\"\n",
        "    weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
        "    model = efficientnet_b0(weights=weights)\n",
        "    model.classifier = nn.Identity()\n",
        "    model.eval()\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "# -----------------------------\n",
        "# Extraction loop\n",
        "# -----------------------------\n",
        "\n",
        "def extract_features_from_folder(split_name: str):\n",
        "    images_dir = PROCESSED_ROOT / split_name / \"images\"\n",
        "    dataset = FundusImageOnlyDataset(images_dir, transform=image_transform)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    model = build_feature_extractor()\n",
        "\n",
        "    all_features = []\n",
        "    all_filenames = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, names in tqdm(dataloader, desc=f\"{split_name} feature extraction\"):\n",
        "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "            feats = model(imgs)               # (B, FEATURE_DIM)\n",
        "            feats = feats.cpu().numpy()\n",
        "\n",
        "            all_features.append(feats)\n",
        "            all_filenames.extend(names)\n",
        "\n",
        "    all_features = np.concatenate(all_features, axis=0)\n",
        "\n",
        "    # Save\n",
        "    split_root = PROCESSED_ROOT / split_name\n",
        "    split_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    feat_path = split_root / f\"{split_name}_features.npy\"\n",
        "    names_path = split_root / f\"{split_name}_filenames.npy\"\n",
        "\n",
        "    np.save(feat_path, all_features)\n",
        "    np.save(names_path, np.array(all_filenames))\n",
        "\n",
        "    print(f\"{split_name}: features shape = {all_features.shape}\")\n",
        "    print(f\"Saved features to {feat_path}\")\n",
        "    print(f\"Saved filenames to {names_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        extract_features_from_folder(split)\n",
        "    print(\"Done.\")\n"
      ],
      "metadata": {
        "id": "a-_-t7oNSzlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786ab8fe-8dce-4afb-ff51-bc77019f078e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 134MB/s] \n",
            "train feature extraction: 100%|██████████| 127/127 [03:00<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: features shape = (4064, 1280)\n",
            "Saved features to /content/drive/MyDrive/processed_dataset/train/train_features.npy\n",
            "Saved filenames to /content/drive/MyDrive/processed_dataset/train/train_filenames.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val feature extraction: 100%|██████████| 28/28 [01:11<00:00,  2.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val: features shape = (870, 1280)\n",
            "Saved features to /content/drive/MyDrive/processed_dataset/val/val_features.npy\n",
            "Saved filenames to /content/drive/MyDrive/processed_dataset/val/val_filenames.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test feature extraction: 100%|██████████| 28/28 [00:53<00:00,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: features shape = (872, 1280)\n",
            "Saved features to /content/drive/MyDrive/processed_dataset/test/test_features.npy\n",
            "Saved filenames to /content/drive/MyDrive/processed_dataset/test/test_filenames.npy\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "CSV_PATH = Path(\"/content/drive/MyDrive/data_csv.csv\")          # update if needed\n",
        "OUT_CSV_PATH = Path(\"/content/drive/MyDrive/data_csv_normalized.csv\")\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 30\n",
        "LR = 1e-3\n",
        "LATENT_DIM = 8   # size of normalized feature vector (change as you like)\n",
        "\n",
        "# numeric feature columns from your CSV\n",
        "NUM_COLS = [\"gender\", \"thickness\", \"True_age\", \"age_norm\"]\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class TabularFeatureDataset(Dataset):\n",
        "    def __init__(self, x: np.ndarray):\n",
        "        self.x = x.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# FC autoencoder normalizer\n",
        "# -----------------------------\n",
        "class TabularNormalizer(nn.Module):\n",
        "    def __init__(self, in_dim: int, latent_dim: int):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(in_dim, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(32, latent_dim),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(32, in_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        recon = self.decoder(z)\n",
        "        return z, recon\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Load CSV and extract numeric features\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    x = df[NUM_COLS].values\n",
        "    in_dim = x.shape[1]\n",
        "\n",
        "    dataset = TabularFeatureDataset(x)\n",
        "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # 2) Train normalizer (autoencoder)\n",
        "    model = TabularNormalizer(in_dim, LATENT_DIM).to(DEVICE)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        epoch_loss = 0.0\n",
        "        for batch in loader:\n",
        "            batch = batch.to(DEVICE)\n",
        "            z, recon = model(batch)\n",
        "            loss = criterion(recon, batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() * batch.size(0)\n",
        "\n",
        "        epoch_loss /= len(dataset)\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, recon MSE: {epoch_loss:.6f}\")\n",
        "\n",
        "    # 3) Get normalized features for all rows\n",
        "    full_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    model.eval()\n",
        "    all_z = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(full_loader, desc=\"Encoding all rows\"):\n",
        "            batch = batch.to(DEVICE)\n",
        "            z, _ = model(batch)\n",
        "            all_z.append(z.cpu().numpy())\n",
        "\n",
        "    all_z = np.concatenate(all_z, axis=0)\n",
        "\n",
        "    # 4) Save back to CSV\n",
        "    for i in range(LATENT_DIM):\n",
        "        df[f\"f{i}\"] = all_z[:, i]\n",
        "\n",
        "    df.to_csv(OUT_CSV_PATH, index=False)\n",
        "    print(f\"Saved normalized features to {OUT_CSV_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEEvovGYnhFV",
        "outputId": "7277db05-298c-4bbd-b9a9-dfa127f4ba4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, recon MSE: 615.450817\n",
            "Epoch 2/30, recon MSE: 603.846178\n",
            "Epoch 3/30, recon MSE: 578.942717\n",
            "Epoch 4/30, recon MSE: 521.525258\n",
            "Epoch 5/30, recon MSE: 403.560743\n",
            "Epoch 6/30, recon MSE: 236.124893\n",
            "Epoch 7/30, recon MSE: 114.552533\n",
            "Epoch 8/30, recon MSE: 73.702872\n",
            "Epoch 9/30, recon MSE: 55.952132\n",
            "Epoch 10/30, recon MSE: 42.705575\n",
            "Epoch 11/30, recon MSE: 30.719453\n",
            "Epoch 12/30, recon MSE: 22.714344\n",
            "Epoch 13/30, recon MSE: 16.780765\n",
            "Epoch 14/30, recon MSE: 13.177212\n",
            "Epoch 15/30, recon MSE: 10.894963\n",
            "Epoch 16/30, recon MSE: 9.137455\n",
            "Epoch 17/30, recon MSE: 7.937293\n",
            "Epoch 18/30, recon MSE: 6.279897\n",
            "Epoch 19/30, recon MSE: 5.870447\n",
            "Epoch 20/30, recon MSE: 5.070012\n",
            "Epoch 21/30, recon MSE: 5.211785\n",
            "Epoch 22/30, recon MSE: 4.806831\n",
            "Epoch 23/30, recon MSE: 3.736278\n",
            "Epoch 24/30, recon MSE: 3.341305\n",
            "Epoch 25/30, recon MSE: 2.984862\n",
            "Epoch 26/30, recon MSE: 3.323820\n",
            "Epoch 27/30, recon MSE: 3.351059\n",
            "Epoch 28/30, recon MSE: 2.664830\n",
            "Epoch 29/30, recon MSE: 2.644258\n",
            "Epoch 30/30, recon MSE: 2.157132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding all rows: 100%|██████████| 23/23 [00:00<00:00, 729.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved normalized features to /content/drive/MyDrive/data_csv_normalized.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Multimodal feature fusion and classification for heart attack risk.\n",
        "\n",
        "Inputs per split (train/val/test):\n",
        "  - Image features: {split}_features.npy  (N, 1280)\n",
        "  - Filenames:      {split}_filenames.npy\n",
        "  - Clinical + normalized features CSV: /content/drive/MyDrive/data_csv_normalized.csv\n",
        "       columns: PatientID, eye, filename, gender, thickness, label, group,\n",
        "                True_age, age_norm, f0..f7\n",
        "\n",
        "Steps:\n",
        "  1. Join image features with clinical latent features f0..f7 using 'filename'.\n",
        "  2. Concatenate -> fused feature of size 1280 + 8 = 1288.\n",
        "  3. Train FC classifier on train, validate on val, evaluate on test.\n",
        "\n",
        "Author: <your name>\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# -----------------------------\n",
        "# Paths and config\n",
        "# -----------------------------\n",
        "BASE = Path(\"/content/drive/MyDrive/processed_dataset\")\n",
        "\n",
        "TRAIN_FEATS = BASE / \"train\" / \"train_features.npy\"\n",
        "TRAIN_NAMES = BASE / \"train\" / \"train_filenames.npy\"\n",
        "\n",
        "VAL_FEATS   = BASE / \"val\" / \"val_features.npy\"\n",
        "VAL_NAMES   = BASE / \"val\" / \"val_filenames.npy\"\n",
        "\n",
        "TEST_FEATS  = BASE / \"test\" / \"test_features.npy\"\n",
        "TEST_NAMES  = BASE / \"test\" / \"test_filenames.npy\"\n",
        "\n",
        "CLIN_CSV = Path(\"/content/drive/MyDrive/data_csv_normalized.csv\")\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "NUM_EPOCHS = 30\n",
        "IMAGE_FEAT_DIM = 1280\n",
        "CLIN_FEAT_COLS = [f\"f{i}\" for i in range(8)]   # from normalization step\n",
        "FUSED_DIM = IMAGE_FEAT_DIM + len(CLIN_FEAT_COLS)\n",
        "\n",
        "# -----------------------------\n",
        "# Data preparation\n",
        "# -----------------------------\n",
        "\n",
        "def load_split(\n",
        "    feat_path: Path,\n",
        "    name_path: Path,\n",
        "    clin_df: pd.DataFrame\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    For one split, align image features and clinical features via filename,\n",
        "    then return fused features and labels.\n",
        "    \"\"\"\n",
        "    img_feats = np.load(feat_path)          # (N, 1280)\n",
        "    filenames = np.load(name_path)          # (N,)\n",
        "\n",
        "    # Map filename -> row in clinical CSV\n",
        "    clin_sub = clin_df.set_index(\"filename\").loc[filenames]\n",
        "    clin_feats = clin_sub[CLIN_FEAT_COLS].values.astype(np.float32)  # (N, 8)\n",
        "    labels = clin_sub[\"label\"].values.astype(np.int64)               # (N,)\n",
        "\n",
        "    # Concatenate image + clinical latent features\n",
        "    fused = np.concatenate([img_feats.astype(np.float32), clin_feats], axis=1)\n",
        "\n",
        "    assert fused.shape[0] == labels.shape[0]\n",
        "    return fused, labels\n",
        "\n",
        "\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, x: np.ndarray, y: np.ndarray):\n",
        "        self.x = x.astype(np.float32)\n",
        "        self.y = y.astype(np.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "\n",
        "class FusionClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple fully connected classifier on fused features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),          # binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.net(x)\n",
        "        return logits.view(-1)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Training & evaluation loops\n",
        "# -----------------------------\n",
        "\n",
        "def run_epoch(model, loader, criterion, optimizer=None):\n",
        "    is_train = optimizer is not None\n",
        "    model.train(is_train)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    all_targets, all_probs = [], []\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb.float())\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "        all_targets.append(yb.cpu().numpy())\n",
        "\n",
        "    total_loss /= len(loader.dataset)\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "\n",
        "    preds = (all_probs >= 0.5).astype(int)\n",
        "    acc = accuracy_score(all_targets, preds)\n",
        "    try:\n",
        "        auc = roc_auc_score(all_targets, all_probs)\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return total_loss, acc, auc\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Load clinical CSV\n",
        "    clin_df = pd.read_csv(CLIN_CSV)\n",
        "\n",
        "    # 2. Build fused features for each split\n",
        "    x_train, y_train = load_split(TRAIN_FEATS, TRAIN_NAMES, clin_df)\n",
        "    x_val,   y_val   = load_split(VAL_FEATS,   VAL_NAMES,   clin_df)\n",
        "    x_test,  y_test  = load_split(TEST_FEATS,  TEST_NAMES,  clin_df)\n",
        "\n",
        "    print(\"Train fused:\", x_train.shape, \"Val fused:\", x_val.shape, \"Test fused:\", x_test.shape)\n",
        "\n",
        "    train_ds = FusionDataset(x_train, y_train)\n",
        "    val_ds   = FusionDataset(x_val,   y_val)\n",
        "    test_ds  = FusionDataset(x_test,  y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # 3. Model, loss, optimizer\n",
        "    model = FusionClassifier(FUSED_DIM).to(DEVICE)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "\n",
        "    best_val_auc = 0.0\n",
        "    best_state = None\n",
        "\n",
        "    # 4. Training loop\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        train_loss, train_acc, train_auc = run_epoch(model, train_loader, criterion, optimizer)\n",
        "        val_loss, val_acc, val_auc = run_epoch(model, val_loader, criterion, optimizer=None)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d} | \"\n",
        "            f\"Train loss {train_loss:.4f}, acc {train_acc:.3f}, AUC {train_auc:.3f} | \"\n",
        "            f\"Val loss {val_loss:.4f}, acc {val_acc:.3f}, AUC {val_auc:.3f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            best_state = model.state_dict().copy()\n",
        "\n",
        "    # 5. Test evaluation using best model\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    test_loss, test_acc, test_auc = run_epoch(model, test_loader, criterion, optimizer=None)\n",
        "    print(f\"TEST | loss {test_loss:.4f}, acc {test_acc:.3f}, AUC {test_auc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc7mqJnFwb2-",
        "outputId": "b048cbde-f24f-490e-ed69-e4e0aaaab788"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train fused: (4064, 1288) Val fused: (870, 1288) Test fused: (872, 1288)\n",
            "Epoch 01 | Train loss 0.4395, acc 0.804, AUC 0.852 | Val loss 0.3869, acc 0.824, AUC 0.882\n",
            "Epoch 02 | Train loss 0.3240, acc 0.860, AUC 0.922 | Val loss 0.4828, acc 0.783, AUC 0.923\n",
            "Epoch 03 | Train loss 0.2453, acc 0.900, AUC 0.958 | Val loss 0.2912, acc 0.879, AUC 0.938\n",
            "Epoch 04 | Train loss 0.2003, acc 0.916, AUC 0.972 | Val loss 0.3748, acc 0.853, AUC 0.948\n",
            "Epoch 05 | Train loss 0.1666, acc 0.933, AUC 0.981 | Val loss 0.3017, acc 0.874, AUC 0.951\n",
            "Epoch 06 | Train loss 0.1487, acc 0.938, AUC 0.985 | Val loss 0.2271, acc 0.897, AUC 0.961\n",
            "Epoch 07 | Train loss 0.1390, acc 0.947, AUC 0.986 | Val loss 0.5169, acc 0.825, AUC 0.954\n",
            "Epoch 08 | Train loss 0.1242, acc 0.951, AUC 0.989 | Val loss 0.3149, acc 0.871, AUC 0.955\n",
            "Epoch 09 | Train loss 0.0909, acc 0.966, AUC 0.995 | Val loss 0.2281, acc 0.907, AUC 0.965\n",
            "Epoch 10 | Train loss 0.0838, acc 0.968, AUC 0.995 | Val loss 0.2614, acc 0.908, AUC 0.962\n",
            "Epoch 11 | Train loss 0.0893, acc 0.967, AUC 0.994 | Val loss 0.4482, acc 0.841, AUC 0.943\n",
            "Epoch 12 | Train loss 0.0906, acc 0.962, AUC 0.994 | Val loss 0.2474, acc 0.918, AUC 0.962\n",
            "Epoch 13 | Train loss 0.0827, acc 0.964, AUC 0.995 | Val loss 0.3734, acc 0.869, AUC 0.961\n",
            "Epoch 14 | Train loss 0.0710, acc 0.973, AUC 0.996 | Val loss 0.2931, acc 0.899, AUC 0.962\n",
            "Epoch 15 | Train loss 0.0621, acc 0.977, AUC 0.997 | Val loss 0.2788, acc 0.906, AUC 0.965\n",
            "Epoch 16 | Train loss 0.0680, acc 0.974, AUC 0.997 | Val loss 0.3183, acc 0.893, AUC 0.955\n",
            "Epoch 17 | Train loss 0.0733, acc 0.972, AUC 0.996 | Val loss 0.3925, acc 0.871, AUC 0.963\n",
            "Epoch 18 | Train loss 0.0661, acc 0.974, AUC 0.997 | Val loss 0.3438, acc 0.887, AUC 0.962\n",
            "Epoch 19 | Train loss 0.0579, acc 0.979, AUC 0.997 | Val loss 0.3053, acc 0.901, AUC 0.958\n",
            "Epoch 20 | Train loss 0.0501, acc 0.982, AUC 0.998 | Val loss 0.4460, acc 0.880, AUC 0.938\n",
            "Epoch 21 | Train loss 0.0562, acc 0.979, AUC 0.998 | Val loss 0.2836, acc 0.903, AUC 0.960\n",
            "Epoch 22 | Train loss 0.0510, acc 0.980, AUC 0.998 | Val loss 0.3373, acc 0.893, AUC 0.953\n",
            "Epoch 23 | Train loss 0.0464, acc 0.982, AUC 0.998 | Val loss 0.3850, acc 0.907, AUC 0.958\n",
            "Epoch 24 | Train loss 0.0464, acc 0.982, AUC 0.999 | Val loss 0.3129, acc 0.892, AUC 0.961\n",
            "Epoch 25 | Train loss 0.0395, acc 0.985, AUC 0.999 | Val loss 0.2969, acc 0.907, AUC 0.960\n",
            "Epoch 26 | Train loss 0.0408, acc 0.984, AUC 0.999 | Val loss 0.3102, acc 0.900, AUC 0.959\n",
            "Epoch 27 | Train loss 0.0444, acc 0.985, AUC 0.998 | Val loss 0.3887, acc 0.897, AUC 0.955\n",
            "Epoch 28 | Train loss 0.0368, acc 0.987, AUC 0.999 | Val loss 0.3278, acc 0.907, AUC 0.958\n",
            "Epoch 29 | Train loss 0.0490, acc 0.984, AUC 0.998 | Val loss 0.3388, acc 0.887, AUC 0.959\n",
            "Epoch 30 | Train loss 0.0453, acc 0.984, AUC 0.999 | Val loss 0.3958, acc 0.879, AUC 0.960\n",
            "TEST | loss 0.3725, acc 0.877, AUC 0.956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    accuracy_score,\n",
        ")\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/heart_risk_results\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Evaluate best model on test set (fixed torch.load)\n",
        "# -------------------------------------------------\n",
        "checkpoint_path = OUTPUT_DIR / \"best_model.pth\"\n",
        "\n",
        "# If you are on PyTorch >= 2.6, explicitly set weights_only=False\n",
        "checkpoint = torch.load(checkpoint_path, map_location=DEVICE, weights_only=False)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "def eval_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_targets, all_probs = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb.float())\n",
        "\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            all_probs.append(probs)\n",
        "            all_targets.append(yb.cpu().numpy())\n",
        "\n",
        "    total_loss /= len(loader.dataset)\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "\n",
        "    preds = (all_probs >= 0.5).astype(int)\n",
        "    acc = accuracy_score(all_targets, preds)\n",
        "    try:\n",
        "        auc = roc_auc_score(all_targets, all_probs)\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return total_loss, acc, auc, all_targets, all_probs\n",
        "\n",
        "test_loss, test_acc, test_auc, y_true, y_prob = eval_epoch(\n",
        "    model, test_loader, criterion\n",
        ")\n",
        "print(f\"TEST | loss {test_loss:.4f}, acc {test_acc:.3f}, AUC {test_auc:.3f}\")\n",
        "\n",
        "np.save(OUTPUT_DIR / \"y_true.npy\", y_true)\n",
        "np.save(OUTPUT_DIR / \"y_prob.npy\", y_prob)\n",
        "\n",
        "# -----------------------------\n",
        "# ROC curve\n",
        "# -----------------------------\n",
        "from sklearn.metrics import roc_curve  # [web:142]\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC (AUC = {test_auc:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Heart Risk Classifier\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"roc_curve.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# -----------------------------\n",
        "# Confusion matrix\n",
        "# -----------------------------\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  # [web:137][web:143]\n",
        "\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
        "plt.title(\"Confusion Matrix - Heart Risk Classifier\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"confusion_matrix.png\", dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(f\"Saved ROC curve and confusion matrix to {OUTPUT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1N6OmzazRNw",
        "outputId": "b647d2bb-5f93-43a4-9631-cd66efade94c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST | loss 0.3915, acc 0.882, AUC 0.959\n",
            "Saved ROC curve and confusion matrix to /content/drive/MyDrive/heart_risk_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/heart_risk_results\")\n",
        "\n",
        "# If y_true and y_prob are still in memory from the previous cell, you can skip loading.\n",
        "# Otherwise, load them from the saved .npy files:\n",
        "y_true = np.load(OUTPUT_DIR / \"y_true.npy\")\n",
        "y_prob = np.load(OUTPUT_DIR / \"y_prob.npy\")\n",
        "\n",
        "# Convert probabilities to binary predictions with threshold 0.5\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "# Binary classification metrics (positive class = 1)\n",
        "precision = precision_score(y_true, y_pred, pos_label=1)\n",
        "recall    = recall_score(y_true, y_pred, pos_label=1)\n",
        "f1        = f1_score(y_true, y_pred, pos_label=1)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")\n",
        "\n",
        "# Optional: full classification report (per class + averages)\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_true, y_pred, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzaaQB4k0O0n",
        "outputId": "3c242e41-1220-43d8-e630-fa244e342269"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.969\n",
            "Recall:    0.862\n",
            "F1-score:  0.913\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.729     0.931     0.818       248\n",
            "           1      0.969     0.862     0.913       624\n",
            "\n",
            "    accuracy                          0.882       872\n",
            "   macro avg      0.849     0.897     0.865       872\n",
            "weighted avg      0.901     0.882     0.886       872\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jn-wFDry2htT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}